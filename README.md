# create-bzp-agent

A simple CLI tool to generate boilerplate code for AI agent applications using Fastify, AI SDK, and Zod.

**âœ¨ Seamless Experience**: Automatically sets up Ollama with a lightweight model (qwen:0.5b) so you can start building immediately without API keys!

## Installation & Usage

### Run from GitHub (no installation needed)

```bash
npx github:your-username/create-bzp-agent <name-of-the-agent>
```

### Install globally

```bash
npm install -g github:your-username/create-bzp-agent
create-bzp-agent <name-of-the-agent>
```

### Or use directly

```bash
create-bzp-agent <name-of-the-agent>
```

The `-agent` suffix will be automatically added if not present.

### Examples

```bash
create-bzp-agent my-agent
# Creates: my-agent/

create-bzp-agent chatbot
# Creates: chatbot-agent/

create-bzp-agent text-processor-agent
# Creates: text-processor-agent/
```

## Generated Structure

The CLI generates the following structure:

```
<name>-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.ts      # Fastify server with POST endpoint
â”‚   â”œâ”€â”€ prompt.ts      # System prompt and Zod schema
â”‚   â”œâ”€â”€ types.ts       # TypeScript types for input/output
â”‚   â””â”€â”€ ai.ts          # AI module handling agent logic
â”œâ”€â”€ .env.example       # Environment variables template
â”œâ”€â”€ package.json       # Dependencies and scripts
â”œâ”€â”€ tsconfig.json      # TypeScript configuration
â””â”€â”€ .gitignore         # Git ignore file
```

## What Happens When You Run It

The CLI will:
1. âœ… Generate all boilerplate files
2. ğŸ” Check if Ollama is installed (optional but recommended)
3. ğŸ“¥ Pull the `qwen:0.5b` model (if Ollama is available)
4. ğŸ“¦ Install dependencies automatically
5. ğŸ‰ Your agent is ready to run!

## Next Steps

After generating:

```bash
cd <name>-agent
pnpm dev
```

That's it! Your agent runs on `http://localhost:8090` using Ollama locally.

**Note**: If Ollama isn't installed, the project still works. You can:
- Install Ollama later: https://ollama.ai
- Or configure Azure OpenAI/OpenAI in `.env`

## Stack

- **Fastify** - Web server framework
- **AI SDK** - AI model integration
- **Ollama** - Local AI models (default, no API keys needed!)
- **Zod** - Schema validation
- **dotenv** - Environment variable management
- **TypeScript** - Type safety

## Model Options

By default, the generated agent uses **Ollama with qwen:0.5b** (lightweight, runs locally).

You can also configure:
- **Azure OpenAI** - Set `AZURE_OPENAI_*` in `.env`
- **OpenAI** - Set `OPENAI_API_KEY` in `.env`
- **Other Ollama models** - Change `OLLAMA_MODEL` in `.env`

