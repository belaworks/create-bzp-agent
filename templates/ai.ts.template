import { createOllama } from "@ai-sdk/ollama";
import { generateObject } from "ai";
import { {{promptName}}, {{schemaName}} } from "./prompt";

const ollama = createOllama({
  baseURL: process.env.OLLAMA_BASE_URL || "http://localhost:11434",
});

const model = process.env.OLLAMA_MODEL || "llama3.2:1b";

export const {{agentFunction}} = async (input: string) => {
  const result = await generateObject({
    model: ollama(model),
    schema: {{schemaName}},
    system: {{promptName}},
    messages: [
      {
        role: "user",
        content: input,
      },
    ],
  });

  return result.object;
};

